{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the `requirements.txt` for this course from the workspace of this lab. `File --> Open...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Create Agents to Research and Write an Article\n",
    "\n",
    "In this lesson, you will be introduced to the foundational concepts of multi-agent systems and get an overview of the crewAI framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries are already installed in the classroom. If you're running this notebook on your own machine, you can install the following:\n",
    "```Python\n",
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crewai==0.28.8\n",
      "  Obtaining dependency information for crewai==0.28.8 from https://files.pythonhosted.org/packages/d2/78/dd949ea0d914ce306821067a886b3520755b59df71cd868a2997cc90a7a5/crewai-0.28.8-py3-none-any.whl.metadata\n",
      "  Downloading crewai-0.28.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting crewai_tools==0.1.6\n",
      "  Obtaining dependency information for crewai_tools==0.1.6 from https://files.pythonhosted.org/packages/de/35/7b0ab9c9de202d2fc22dc183ec9da28c992038938f1e06684f72ba15eb55/crewai_tools-0.1.6-py3-none-any.whl.metadata\n",
      "  Downloading crewai_tools-0.1.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langchain_community==0.0.29\n",
      "  Obtaining dependency information for langchain_community==0.0.29 from https://files.pythonhosted.org/packages/e1/80/4136757bf245f60e2f4e148adb340207ea330be92bc26727bca32fe6bc48/langchain_community-0.0.29-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.10/site-packages (from crewai==0.28.8) (1.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/site-packages (from crewai==0.28.8) (8.1.8)\n",
      "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/fb/57/c9294d3f7eae142f6dfe77eda6e1541923c7ad5ebf389cb07f9ada6c53a2/embedchain-0.1.126-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting instructor<0.6.0,>=0.5.2 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for instructor<0.6.0,>=0.5.2 from https://files.pythonhosted.org/packages/3d/57/35e22db00463ac2a2f57e7b8823d0084c5e83f69d518313bdfbf61764463/instructor-0.5.2-py3-none-any.whl.metadata\n",
      "  Downloading instructor-0.5.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain<0.2.0,>=0.1.10 from https://files.pythonhosted.org/packages/4b/28/da40a6b12e7842a0c8b443f8cc5c6f59e49d7a9071cfad064b9639c6b044/langchain-0.1.20-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /usr/local/lib/python3.10/site-packages (from crewai==0.28.8) (1.59.7)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/site-packages (from crewai==0.28.8) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/site-packages (from crewai==0.28.8) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/site-packages (from crewai==0.28.8) (1.29.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/site-packages (from crewai==0.28.8) (2.10.5)\n",
      "Collecting python-dotenv==1.0.0 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for python-dotenv==1.0.0 from https://files.pythonhosted.org/packages/44/2f/62ea1c8b593f4e093cc1a7768f0d46112107e790c3e478532329e434f00b/python_dotenv-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting regex<2024.0.0,>=2023.12.25 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for regex<2024.0.0,>=2023.12.25 from https://files.pythonhosted.org/packages/8a/8d/8c70bce12045fa622949d3fd3e4e64a01b506a3e670dada8c5f9b3be1e34/regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beautifulsoup4<5.0.0,>=4.12.3 (from crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for beautifulsoup4<5.0.0,>=4.12.3 from https://files.pythonhosted.org/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting chromadb<0.5.0,>=0.4.22 (from crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for chromadb<0.5.0,>=0.4.22 from https://files.pythonhosted.org/packages/cc/63/b7d76109331318423f9cfb89bd89c99e19f5d0b47a5105439a629224d297/chromadb-0.4.24-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting lancedb<0.6.0,>=0.5.4 (from crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for lancedb<0.6.0,>=0.5.4 from https://files.pythonhosted.org/packages/01/21/ecb191feff512640a59e17fe1737bd9c33970bc857c59a77fa61d5e314d9/lancedb-0.5.7-py3-none-any.whl.metadata\n",
      "  Downloading lancedb-0.5.7-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pyright<2.0.0,>=1.1.350 (from crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for pyright<2.0.0,>=1.1.350 from https://files.pythonhosted.org/packages/e7/b1/a18de17f40e4f61ca58856b9ef9b0febf74ff88978c3f7776f910071f567/pyright-1.1.392.post0-py3-none-any.whl.metadata\n",
      "  Downloading pyright-1.1.392.post0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting pytest<9.0.0,>=8.0.0 (from crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for pytest<9.0.0,>=8.0.0 from https://files.pythonhosted.org/packages/11/92/76a1c94d3afee238333bc0a42b82935dd8f9cf8ce9e336ff87ee14d9e1cf/pytest-8.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pytube<16.0.0,>=15.0.0 (from crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for pytube<16.0.0,>=15.0.0 from https://files.pythonhosted.org/packages/51/64/bcf8632ed2b7a36bbf84a0544885ffa1d0b4bcf25cc0903dba66ec5fdad9/pytube-15.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/site-packages (from crewai_tools==0.1.6) (2.32.3)\n",
      "Collecting selenium<5.0.0,>=4.18.1 (from crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for selenium<5.0.0,>=4.18.1 from https://files.pythonhosted.org/packages/a0/9f/34d0ec09b0dd6fb7b08b93eb4b7b80049e0b9db0ba7f81ad814c9be78b8f/selenium-4.28.1-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/site-packages (from langchain_community==0.0.29) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/site-packages (from langchain_community==0.0.29) (1.4.46)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/site-packages (from langchain_community==0.0.29) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.0.29)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain_community==0.0.29)\n",
      "  Obtaining dependency information for langchain-core<0.2.0,>=0.1.33 from https://files.pythonhosted.org/packages/6a/10/285fa149ce95300d91ea0bb124eec28889e5ebbcb59434d1fe2f31098d72/langchain_core-0.1.53-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community==0.0.29)\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.0 from https://files.pythonhosted.org/packages/de/f0/63b06b99b730b9954f8709f6f7d9b8d076fa0a973e472efe278089bde42b/langsmith-0.1.147-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/site-packages (from langchain_community==0.0.29) (1.23.5)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain_community==0.0.29)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/d2/3f/8ba87d9e287b9d385a02a7114ddcef61b26f86411e121c9003eb509a1773/tenacity-8.5.0-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.3.2.post1)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.2.post1)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/1a/36/d1069ffa520efcf93f6d81b527e3c7311e12363742fdc786cbdaea3ab02e/chroma_hnswlib-0.7.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.115.6)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.12.2)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/57/aa/2ec1225582623cd3081b1d172ca07622fd68032d867b7a8f479d45f39d16/pulsar_client-3.6.0-cp310-cp310-macosx_13_0_universal2.whl.metadata\n",
      "  Downloading pulsar_client-3.6.0-cp310-cp310-macosx_13_0_universal2.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.50b0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.10.14)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/d6/0d/80d7071803df1957c304bc096a714334dda7eb41ecfdd28dcfb49b1cde0e/marshmallow-3.26.0-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for alembic<2.0.0,>=1.13.1 from https://files.pythonhosted.org/packages/54/7e/ac0991d1745f7d755fc1cd381b3990a45b404b4d008fc75e2a983516fbfe/alembic-1.14.1-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/52/82/3d0355c22bc68cfbb8fbcf670da4c01b31bd7eb516974a08cf7533e89887/embedchain-0.1.125-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.125-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/d0/f2/55288753b4d3bc6c608f7a0ec9f00522b3a95c587b5dd6e7581587568313/embedchain-0.1.124-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.124-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for cohere<6.0,>=5.3 from https://files.pythonhosted.org/packages/02/84/119fd98f3271efbc072e8d253fc39fcc8d8763a3dfcff8139feaa4548878/cohere-5.13.11-py3-none-any.whl.metadata\n",
      "  Downloading cohere-5.13.11-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-cloud-aiplatform<2.0.0,>=1.26.1 from https://files.pythonhosted.org/packages/86/d3/e829951c5cba9267c9a01d783812ccc679dc48cc3e265e8d1829806192b6/google_cloud_aiplatform-1.78.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_aiplatform-1.78.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for gptcache<0.2.0,>=0.1.43 from https://files.pythonhosted.org/packages/49/87/8dde0a3757bc207805f751b47878888b09db4a464ae48a55f386f091b488/gptcache-0.1.44-py3-none-any.whl.metadata\n",
      "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/a7/51/0c78d26da4afbe68370306669556b274f1021cac02f3155d8da2be407763/embedchain-0.1.123-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/95/3f/42c97c1d3c9483076843987982a018115b6a28be02091fb475e6dbc743f2/embedchain-0.1.122-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.122-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/49/54/37fa96129096ce64b64db3a23693a0df607a31c62e300dd9bd27d13e0688/embedchain-0.1.121-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.121-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/7b/f2/47be405e37d15e4dfb8ecc133d16cac623a11385f5ca9f58691190e4433c/embedchain-0.1.120-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.120-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/84/60/5c92e19bf40e778d1844039dcb2a39e6f375adbfa0d7a7d33c7050fb67a8/embedchain-0.1.119-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.119-py3-none-any.whl.metadata (9.1 kB)\n",
      "INFO: pip is still looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/ef/53/f41a39e9e488cb19e59b35e541758be191cd286092c45a510fa4e11f35ca/embedchain-0.1.118-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.118-py3-none-any.whl.metadata (9.1 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/1c/aa/4e8a47f2f2960c63b790b264f1de4f201171863943a6e3b204a9d72faf52/embedchain-0.1.117-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.117-py3-none-any.whl.metadata (9.1 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/c4/ab/aebea68f64c18ea83d56c721b16d75c481a008f6f1ce8cee42b93f50515b/embedchain-0.1.116-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.116-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting clarifai<11.0.0,>=10.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for clarifai<11.0.0,>=10.0.1 from https://files.pythonhosted.org/packages/8d/ad/0d9abd0a459c7d5e1a71128b1e32664de9e00c8255d15c0102153c25a801/clarifai-10.11.1-py3-none-any.whl.metadata\n",
      "  Downloading clarifai-10.11.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/61/66/711963e8785d4638e5aaeca557490c2bb86b77e360aa2501d4eb2830623e/embedchain-0.1.115-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.115-py3-none-any.whl.metadata (10 kB)\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/84/51/43a6d1395fdb47ce506d57010bd05a69cd79cdeba422806fa69f4b57fb17/embedchain-0.1.114-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.114-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Obtaining dependency information for embedchain<0.2.0,>=0.1.98 from https://files.pythonhosted.org/packages/c0/9c/42c0841245935d0388df0d9f179a51585745097227650d9525b4eac22b0d/embedchain-0.1.113-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.1.113-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain-cohere<0.2.0,>=0.1.4 from https://files.pythonhosted.org/packages/52/b1/ee8d44898cfe43703f05a0ffd95294d3ebe4c61879f19c6357c860131312/langchain_cohere-0.1.9-py3-none-any.whl.metadata\n",
      "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/7f/2e/a4430cad7a98e29e9612648f8b12d7449ab635a742c19bf1d62f8713ecaa/langchain_openai-0.1.25-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for pypdf<5.0.0,>=4.0.1 from https://files.pythonhosted.org/packages/3c/60/eccdd92dd4af3e4bea6d6a342f7588c618a15b9bec4b968af581e498bcc4/pypdf-4.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for pysbd<0.4.0,>=0.3.4 from https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.9.4)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for schema<0.8.0,>=0.7.5 from https://files.pythonhosted.org/packages/ad/1b/81855a88c6db2b114d5b2e9f96339190d5ee4d1b981d217fa32127bb00e0/schema-0.7.7-py2.py3-none-any.whl.metadata\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community==0.0.29)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/80/21/aaf0cd2e7ee56e464af7cba38a54f9c1203570181ec5d847711f33c9f520/SQLAlchemy-2.0.37-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.37-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting tiktoken<0.8.0,>=0.7.0 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for tiktoken<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/96/10/28d59d43d72a0ebd4211371d0bf10c935cdecbb62b812ae04c58bfc37d96/tiktoken-0.7.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is still looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for youtube-transcript-api<0.7.0,>=0.6.1 from https://files.pythonhosted.org/packages/80/d4/be6fd091d29ae49d93813e598769e7ab453419a4de640e1755bf20911cce/youtube_transcript_api-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for yt_dlp<2024.0.0,>=2023.11.14 from https://files.pythonhosted.org/packages/d6/69/da2592056798716027215f561f2e9eeb3384d48b6b6a5a918916dbad1c98/yt_dlp-2023.12.30-py2.py3-none-any.whl.metadata\n",
      "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl.metadata (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyGithub<2.0.0,>=1.59.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for PyGithub<2.0.0,>=1.59.1 from https://files.pythonhosted.org/packages/2c/71/aff5465d9e3d448a5d4beab1dc7c8dec72037e3ae7e0d856ee08538dc934/PyGithub-1.59.1-py3-none-any.whl.metadata\n",
      "  Downloading PyGithub-1.59.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting gitpython<4.0.0,>=3.1.38 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for gitpython<4.0.0,>=3.1.38 from https://files.pythonhosted.org/packages/1d/9a/4114a9057db2f1462d5c8f8390ab7383925fe1ac012eaa42402ad65c2963/GitPython-3.1.44-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai==0.28.8)\n",
      "  Obtaining dependency information for docstring-parser<0.16,>=0.15 from https://files.pythonhosted.org/packages/89/e3/32e272db7adcf90e93f73e9a98fd763049ed7c641fb57ab26cb8f3e7e79c/docstring_parser-0.15-py3-none-any.whl.metadata\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for typer>=0.9.0 from https://files.pythonhosted.org/packages/62/39/82c9d3e10979851847361d922a373bdfef4091020da7f893acfaf07c0225/typer-0.9.4-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: deprecation in /usr/local/lib/python3.10/site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (2.1.0)\n",
      "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for pylance==0.9.18 from https://files.pythonhosted.org/packages/ca/b8/15d4d380f0858dde46d42891776017e3bf9eb40129b3fe222637eecf8f43/pylance-0.9.18-cp38-abi3-macosx_10_15_x86_64.whl.metadata\n",
      "  Downloading pylance-0.9.18-cp38-abi3-macosx_10_15_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for ratelimiter~=1.0 from https://files.pythonhosted.org/packages/51/80/2164fa1e863ad52cc8d870855fba0fbb51edd943edffd516d54b5f6f8ff8/ratelimiter-1.2.0.post0-py3-none-any.whl.metadata\n",
      "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for retry>=0.9.2 from https://files.pythonhosted.org/packages/4b/0d/53aea75710af4528a25ed6837d71d117602b01946b307a3912cb3cfcbcba/retry-0.9.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for semver>=3.0 from https://files.pythonhosted.org/packages/a6/24/4d91e05817e92e3a61c8a21e08fd0f390f5301f1c448b137c57c4bc6e543/semver-3.0.4-py3-none-any.whl.metadata\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.2.1)\n",
      "Collecting pyarrow>=12 (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for pyarrow>=12 from https://files.pythonhosted.org/packages/1b/f0/adab5f142eb8203db8bfbd3a816816e37a85423ae684567e7f3555658315/pyarrow-19.0.0-cp310-cp310-macosx_12_0_x86_64.whl.metadata\n",
      "  Downloading pyarrow-19.0.0-cp310-cp310-macosx_12_0_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29)\n",
      "  Obtaining dependency information for async-timeout<6.0,>=4.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain<0.2.0,>=0.1.10 from https://files.pythonhosted.org/packages/6e/fd/03ba22f02923238512b639a608da59ea0d1ee664e53691bd12b47130df58/langchain-0.1.19-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for langchain<0.2.0,>=0.1.10 from https://files.pythonhosted.org/packages/c8/bc/607cd3254800a26b60da9e2ca6b10785e60170db7e85dc3d0328b5ab3a9c/langchain-0.1.17-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain<0.2.0,>=0.1.10 from https://files.pythonhosted.org/packages/ed/3e/93045d37eba24e0b5eb05312e30cd9e12805ea5f1ae9ba51ec8a7d2f5372/langchain-0.1.16-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for langchain<0.2.0,>=0.1.10 from https://files.pythonhosted.org/packages/70/20/0f4546a7c4de5f07f11d52316f9cbb13817ce37c8a9ba2c230e32c7c125f/langchain-0.1.15-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for langchain<0.2.0,>=0.1.10 from https://files.pythonhosted.org/packages/d5/d0/5e0bbcabe42f9e09c66fa0964b2ecdfee9a92cb2d7f05dd340b93203a40a/langchain-0.1.14-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for langchain<0.2.0,>=0.1.10 from https://files.pythonhosted.org/packages/f8/1b/697dec4ff03114b049b687d4fdbdcefdfff365868876ec58c1ab2cf75253/langchain-0.1.13-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.1,>=0.0.1 from https://files.pythonhosted.org/packages/68/6a/804fe5ca07129046a4cedc0697222ddde6156cd874c4c4ba29e4d271828a/langchain_text_splitters-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.27.2)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29)\n",
      "  Obtaining dependency information for requests-toolbelt<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/site-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (3.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/site-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.2.13)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.29.0)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-proto==1.29.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (5.29.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8) (0.50b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.27.2)\n",
      "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for nodeenv>=1.6.0 from https://files.pythonhosted.org/packages/d2/1d/1b658dbd2b9fa9c4c9f32accbfc0205d532c8c6194dc0f2a4c0428e7128a/nodeenv-1.9.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc8 (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for exceptiongroup>=1.0.0rc8 from https://files.pythonhosted.org/packages/02/cc/b7e31358aac6ed1ef2bb790a9746ac2c69bcb3c8588b41616914eb106eaf/exceptiongroup-1.2.2-py3-none-any.whl.metadata\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting iniconfig (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for iniconfig from https://files.pythonhosted.org/packages/ef/a6/62565a6e1cf69e10f5727360368e451d4b7f58beeac6173dc9db836a5b46/iniconfig-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for pluggy<2,>=1.5 from https://files.pythonhosted.org/packages/88/5f/e351af9a41f866ac3f1fac4ca0613908d9a41741cfcf2228f4ad853b697d/pluggy-1.5.0-py3-none-any.whl.metadata\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/site-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2022.12.7)\n",
      "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/b4/04/9954a59e1fb6732f5436225c9af963811d7b24ea62a8bf96991f2cb8c26e/trio-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client~=1.8 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for websocket-client~=1.8 from https://files.pythonhosted.org/packages/5a/84/44687a29792a70e111c5c477230a72c4b957d88d16141199bf9acb7537a3/websocket_client-1.8.0-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (2.0.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/site-packages (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.2.4)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.0.0)\n",
      "Collecting clarifai-grpc>=10.11.2 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for clarifai-grpc>=10.11.2 from https://files.pythonhosted.org/packages/57/a6/4a99bd35fb0d94cf717adfc60240657728cb3cb6ba6ebe79014ac88a6c79/clarifai_grpc-11.0.5-py3-none-any.whl.metadata\n",
      "  Downloading clarifai_grpc-11.0.5-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for clarifai-protocol>=0.0.14 from https://files.pythonhosted.org/packages/3d/e9/40e919167da41f1e40729c7e6ab88d43661a25d11cb4f6f767c3bcc693b0/clarifai_protocol-0.0.16-cp310-cp310-macosx_11_0_universal2.whl.metadata\n",
      "  Downloading clarifai_protocol-0.0.16-cp310-cp310-macosx_11_0_universal2.whl.metadata (14 kB)\n",
      "Collecting tritonclient>=2.34.0 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for tritonclient>=2.34.0 from https://files.pythonhosted.org/packages/9d/f1/45ed11610d87baf36dcc2d4ebccdbf211e6dca551e8ff4015a9ebf5d4c4f/tritonclient-2.53.0-py3-none-any.whl.metadata\n",
      "  Downloading tritonclient-2.53.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain_community==0.0.29)\n",
      "  Obtaining dependency information for PyYAML>=5.3 from https://files.pythonhosted.org/packages/9b/95/a3fac87cb7158e231b5a6012e438c647e1a87f09f8e0d123acec8ab8bf71/PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for schema<0.8.0,>=0.7.5 from https://files.pythonhosted.org/packages/0d/93/ca8aa5a772efd69043d0a745172d92bee027caa7565c7f774a2f44b91207/schema-0.7.5-py2.py3-none-any.whl.metadata\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting Pillow>=9.5.0 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for Pillow>=9.5.0 from https://files.pythonhosted.org/packages/50/1c/2dcea34ac3d7bc96a1fd1bd0a6e06a57c67167fec2cff8d95d88229a8817/pillow-11.1.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata\n",
      "  Downloading pillow-11.1.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting inquirerpy==0.3.4 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for inquirerpy==0.3.4 from https://files.pythonhosted.org/packages/ce/ff/3b59672c47c6284e8005b42e84ceba13864aa0f39f067c973d1af02f5d91/InquirerPy-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.9.0)\n",
      "Collecting fsspec==2024.6.1 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for fsspec==2024.6.1 from https://files.pythonhosted.org/packages/5e/44/73bea497ac69bafde2ee4269292fa3b41f1198f4bb7bbaaabde30ad29d4a/fsspec-2024.6.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from crewai==0.28.8)\n",
      "  Obtaining dependency information for click<9.0.0,>=8.1.7 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/site-packages (from schema<0.8.0,>=0.7.5->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (21.6.0)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for pfzy<0.4.0,>=0.3.1 from https://files.pythonhosted.org/packages/8c/d7/8ff98376b1acc4503253b685ea09981697385ce344d4e3935c2af49e044d/pfzy-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/site-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.36)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.14.1)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.41.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/site-packages (from gitpython<4.0.0,>=3.1.38->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.0.10)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 from https://files.pythonhosted.org/packages/b1/a6/8e30ddfd3d39ee6d2c76d3d4f64a83f77ac86a4cab67b286ae35ce9e4369/google_api_core-2.24.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.16.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.3 from https://files.pythonhosted.org/packages/42/c3/59308ccc07b34980f9d532f7afc718a9f32b40e52cde7a740df8d55632fb/proto_plus-1.26.0-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-cloud-storage<3.0.0dev,>=1.32.0 from https://files.pythonhosted.org/packages/d5/94/6db383d8ee1adf45dc6c73477152b82731fa4c4a46d9c1932cc8757e0fd4/google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 from https://files.pythonhosted.org/packages/68/60/9e1430f0fe17f8e8e931eff468021516f74f2573f261221529767dd59591/google_cloud_bigquery-3.29.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_bigquery-3.29.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-cloud-resource-manager<3.0.0dev,>=1.3.3 from https://files.pythonhosted.org/packages/64/c4/2275ca35419f9a2ae66846f389490b356856bf55a9ad9f95a88399a89294/google_cloud_resource_manager-1.14.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_resource_manager-1.14.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for shapely<3.0.0dev from https://files.pythonhosted.org/packages/17/d4/f84bbbdb7771f5b9ade94db2398b256cf1471f1eb0ca8afbe0f6ca725d5a/shapely-2.0.6-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading shapely-2.0.6-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (2.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.8.2)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.9)\n",
      "INFO: pip is looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain-cohere<0.2.0,>=0.1.4 from https://files.pythonhosted.org/packages/ed/8f/11f8e67287a34363c89c0f17c28251133ae640ebc363777b06b8db1cb793/langchain_cohere-0.1.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain_cohere-0.1.8-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Obtaining dependency information for langchain-cohere<0.2.0,>=0.1.4 from https://files.pythonhosted.org/packages/32/91/d89fbfe3aae96189df7cc8ae897197acb9306fe5c24f6455e8a4bfaa2591/langchain_cohere-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading langchain_cohere-0.1.7-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Obtaining dependency information for langchain-cohere<0.2.0,>=0.1.4 from https://files.pythonhosted.org/packages/a5/ad/e278f7c61a1e90c5f504807064e881b3b1201eef6ba8f5fbd367953bf369/langchain_cohere-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_cohere-0.1.5-py3-none-any.whl.metadata (6.4 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/44/5b/7c80b53d372cff285d04887de9c59b69657fcd30039ff986f22e7bea4471/langchain_openai-0.1.24-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/0e/f1/12cd80e136b6bf5f498bee178084e71d48f664e5639e9cc7f900244d9f1c/langchain_openai-0.1.23-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/bb/82/6d6cb06f3fa41610918815a852ac7a2f067ec79df76c8d651014f12d6c31/langchain_openai-0.1.22-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/aa/1c/aebc87392546cb90e143e299a3454b2fcecd8055ad73d6c09a43f5994f71/langchain_openai-0.1.20-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/03/77/53474845dc097eaade5616f1ede46f37bf3e63277b4a7e2c46e8245ed0ab/langchain_openai-0.1.19-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/25/e1/e8a255f391d9eeef36ff6d617c01160f3fce7c5f4ae4ce8250d661336f44/langchain_openai-0.1.17-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/7e/39/7dbd710fea15a80328f1a3c18cc7ce564e1242cbba28902b55733c80177e/langchain_openai-0.1.16-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/51/7d/7330aa9037a7270a5c9f7b0f80e63f4ca86ea377e5594fed1d611b013946/langchain_openai-0.1.15-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/a2/06/d200c9e3f8f17bb50a07df9b7c92894ad5e0c1d65729ea0e438a36371858/langchain_openai-0.1.14-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/5f/40/e904800a5bb989ed9790373455ba0776b67d9900ea3ae64e10f2b667ffe6/langchain_openai-0.1.13-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/8e/1e/f515d661cb902e5e8fd5ebd9b7789cfd3314ec97154c1db8a3b5ad62d515/langchain_openai-0.1.12-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/31/13/a18831a9a1aff3e16b68c1f48a40e20d3a13c6c7c08ac77960a58fdf911f/langchain_openai-0.1.11-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/8c/a7/79f6c6495d6eeb88d4c435cba4fe2e4da5a3d5f608793dc4753033ef2c73/langchain_openai-0.1.10-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/15/bb/e8f080c8408673609f15436237ec8f9d8c39ab67986807d0ca2663acd7a0/langchain_openai-0.1.9-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/95/ac/ec2eaa55a7eea519b17a7687e5bf1387dd313f41cf19750f9cfb96db44f9/langchain_openai-0.1.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Obtaining dependency information for langchain-openai<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/10/27/43f785670a340363fe46e2893a80293fa12448584f19ba4f9e6d03673552/langchain_openai-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (23.1.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.12)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.50b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.2.1)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.4.0 in /usr/local/lib/python3.10/site-packages (from PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.10.1)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in /usr/local/lib/python3.10/site-packages (from PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.5.0)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/site-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.1.1)\n",
      "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for py<2.0.0,>=1.4.26 from https://files.pythonhosted.org/packages/f6/f0/10642828a8dfb741e5f3fbaac830550a518a775c7fff6f04a007259b0548/py-1.11.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.27.1)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29)\n",
      "  Obtaining dependency information for attrs>=17.3.0 from https://files.pythonhosted.org/packages/fc/30/d4986a882011f9df997a55e6becd864812ccfcd821d64aac8570ee39f719/attrs-25.1.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for sortedcontainers from https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
      "  Obtaining dependency information for mypy-extensions>=0.3.0 from https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/site-packages (from urllib3<3,>=1.21.1->requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (1.7.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (14.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/site-packages (from youtube-transcript-api<0.7.0,>=0.6.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.7.1)\n",
      "Collecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for mutagen from https://files.pythonhosted.org/packages/b0/7a/620f945b96be1f6ee357d211d5bf74ab1b7fe72a9f1525aafbfe3aee6875/mutagen-1.47.0-py3-none-any.whl.metadata\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt_dlp<2024.0.0,>=2023.11.14->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for pycryptodomex from https://files.pythonhosted.org/packages/ce/8f/4d0e2a859a6470289d64e39b419f01d2494dfa2e4995342d50f6c2834237/pycryptodomex-3.21.0-cp36-abi3-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-macosx_10_9_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for brotli from https://files.pythonhosted.org/packages/dd/11/afc14026ea7f44bd6eb9316d800d439d092c8d508752055ce8d03086079a/Brotli-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.5 kB)\n",
      "INFO: pip is looking at multiple versions of clarifai-protocol to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for clarifai-protocol>=0.0.14 from https://files.pythonhosted.org/packages/c6/95/6eb2adf787c37c1b16acf164bb8a93d14d060a353e3cd45a87dd839f0c8c/clarifai_protocol-0.0.14-cp310-cp310-macosx_11_0_universal2.whl.metadata\n",
      "  Downloading clarifai_protocol-0.0.14-cp310-cp310-macosx_11_0_universal2.whl.metadata (14 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for fastavro<2.0.0,>=1.9.4 from https://files.pythonhosted.org/packages/0c/e9/f5813450d672f500c4794a39a7cfea99316cb63d5ea11f215e320ea5243b/fastavro-1.10.0-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading fastavro-1.10.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for httpx-sse==0.4.0 from https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for types-requests<3.0.0,>=2.0.0 from https://files.pythonhosted.org/packages/d7/01/485b3026ff90e5190b5e24f1711522e06c79f4a56c8f4b95848ac072e20f/types_requests-2.32.0.20241016-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (5.0.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for grpcio-status<2.0.dev0,>=1.33.2 from https://files.pythonhosted.org/packages/e6/34/49e558040e069feebac70cdd1b605f38738c0277ac5d38e2ce3d03e1b1ec/grpcio_status-1.70.0-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.9)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-cloud-core<3.0.0dev,>=2.4.1 from https://files.pythonhosted.org/packages/5e/0f/2e2061e3fbcb9d535d5da3f58cc8de4947df1786fe6a1355960feb05a681/google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-resumable-media<3.0dev,>=2.0.0 from https://files.pythonhosted.org/packages/82/35/b8d3baf8c46695858cb9d8835a53baa1eeb9906ddaf2f728a5f5b640fd1e/google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for grpc-google-iam-v1<1.0.0dev,>=0.12.4 from https://files.pythonhosted.org/packages/66/b4/ab54f7fda4af43ca5c094bc1d6341780fd669c44ae18952b5337029b1d98/grpc_google_iam_v1-0.14.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading grpc_google_iam_v1-0.14.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-auth<3.0.0dev,>=2.14.1 from https://files.pythonhosted.org/packages/9d/47/603554949a37bca5b7f894d51896a9c534b9eab808e2520a748e081669d0/google_auth-2.38.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for google-crc32c<2.0dev,>=1.0 from https://files.pythonhosted.org/packages/84/3b/29cadae166132e4991087a49dc88906a1d3d5ec22b80f63bc4bc7b6e0431/google_crc32c-1.6.0-cp310-cp310-macosx_12_0_x86_64.whl.metadata\n",
      "  Downloading google_crc32c-1.6.0-cp310-cp310-macosx_12_0_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.10.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/site-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (43.0.3)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/site-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.15.1)\n",
      "Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.34.0->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
      "  Obtaining dependency information for python-rapidjson>=0.9.1 from https://files.pythonhosted.org/packages/39/49/ed3857c5c601fab923e88637efbb68e4d9951bcf5bf2029bb9526cfb3638/python_rapidjson-1.20-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading python_rapidjson-1.20-cp310-cp310-macosx_10_9_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/site-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.21)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
      "  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/b3/17/e65139ea76dac7bcd8a3f17cbd37e3d1a070c44db3098d0be5e14c5bd6a1/grpcio-1.70.0-cp310-cp310-macosx_12_0_universal2.whl.metadata\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.8)\n",
      "Downloading crewai-0.28.8-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m546.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading crewai_tools-0.1.6-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m882.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m--:--\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m569.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-macosx_10_9_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.6/219.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading embedchain-0.1.113-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
      "Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pylance-0.9.18-cp38-abi3-macosx_10_15_x86_64.whl (20.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyright-1.1.392.post0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.1/343.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.37-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading clarifai-10.11.1-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m226.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m372.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_aiplatform-1.78.0-py2.py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_cohere-0.1.5-py3-none-any.whl (30 kB)\n",
      "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading pulsar_client-3.6.0-cp310-cp310-macosx_13_0_universal2.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
      "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m470.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading clarifai_grpc-11.0.5-py3-none-any.whl (261 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.9/261.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading clarifai_protocol-0.0.14-cp310-cp310-macosx_11_0_universal2.whl (206 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.9/206.9 kB\u001b[0m \u001b[31m971.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.13.11-py3-none-any.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading google_cloud_bigquery-3.29.0-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.14.0-py2.py3-none-any.whl (384 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.1/384.1 kB\u001b[0m \u001b[31m418.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pillow-11.1.0-cp310-cp310-macosx_10_10_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.0-cp310-cp310-macosx_12_0_x86_64.whl (32.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.1/32.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp310-cp310-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tritonclient-2.53.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading Brotli-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl (446 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.2/446.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading pycryptodomex-3.21.0-cp36-abi3-macosx_10_9_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading fastavro-1.10.0-cp310-cp310-macosx_10_9_universal2.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.6.0-cp310-cp310-macosx_12_0_x86_64.whl (30 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.14.0-py2.py3-none-any.whl (27 kB)\n",
      "Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.70.0-cp310-cp310-macosx_12_0_universal2.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Downloading python_rapidjson-1.20-cp310-cp310-macosx_10_9_x86_64.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/229.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: sortedcontainers, ratelimiter, brotli, wsproto, websocket-client, types-requests, tenacity, SQLAlchemy, shapely, semver, schema, regex, PyYAML, pytube, python-rapidjson, python-dotenv, pysbd, pypdf, pycryptodomex, pyarrow, py, pulsar-client, proto-plus, pluggy, Pillow, pfzy, packaging, nodeenv, mypy-extensions, mutagen, jsonpatch, iniconfig, httpx-sse, grpcio, google-crc32c, fsspec, fastavro, exceptiongroup, docstring-parser, click, chroma-hnswlib, beautifulsoup4, attrs, async-timeout, yt_dlp, youtube-transcript-api, typing-inspect, typer, tritonclient, tiktoken, retry, requests-toolbelt, pytest, pyright, pylance, outcome, marshmallow, inquirerpy, grpcio-status, gptcache, google-resumable-media, google-auth, gitpython, clarifai-grpc, alembic, trio, langsmith, lancedb, grpc-google-iam-v1, google-api-core, dataclasses-json, trio-websocket, PyGithub, langchain-core, instructor, google-cloud-core, cohere, selenium, langchain-text-splitters, langchain-openai, langchain_community, langchain-cohere, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, langchain, google-cloud-aiplatform, chromadb, clarifai-protocol, clarifai, embedchain, crewai_tools, crewai\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 1.4.2\n",
      "    Uninstalling websocket-client-1.4.2:\n",
      "      Successfully uninstalled websocket-client-1.4.2\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.46\n",
      "    Uninstalling SQLAlchemy-1.4.46:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.46\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 1.0.1\n",
      "    Uninstalling python-dotenv-1.0.1:\n",
      "      Successfully uninstalled python-dotenv-1.0.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 9.0.0\n",
      "    Uninstalling pyarrow-9.0.0:\n",
      "      Successfully uninstalled pyarrow-9.0.0\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.4.0\n",
      "    Uninstalling Pillow-9.4.0:\n",
      "      Successfully uninstalled Pillow-9.4.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.69.0\n",
      "    Uninstalling grpcio-1.69.0:\n",
      "      Successfully uninstalled grpcio-1.69.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: docstring-parser\n",
      "    Found existing installation: docstring_parser 0.16\n",
      "    Uninstalling docstring_parser-0.16:\n",
      "      Successfully uninstalled docstring_parser-0.16\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.8\n",
      "    Uninstalling click-8.1.8:\n",
      "      Successfully uninstalled click-8.1.8\n",
      "  Attempting uninstall: chroma-hnswlib\n",
      "    Found existing installation: chroma-hnswlib 0.7.6\n",
      "    Uninstalling chroma-hnswlib-0.7.6:\n",
      "      Successfully uninstalled chroma-hnswlib-0.7.6\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.1\n",
      "    Uninstalling beautifulsoup4-4.11.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.15.1\n",
      "    Uninstalling typer-0.15.1:\n",
      "      Successfully uninstalled typer-0.15.1\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '/usr/local/LICENSE.txt'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from cryptography.utils import CryptographyDeprecationWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=CryptographyDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import from the crewAI libray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a LLM for your agents, you'll be using OpenAI's `gpt-3.5-turbo`.\n",
    "\n",
    "**Optional Note:** crewAI also allow other popular models to be used as a LLM for your Agents. You can see some of the examples at the [bottom of the notebook](#1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key from the environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents\n",
    "\n",
    "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
    "- It has been seen that LLMs perform better when they are role playing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent: Planner\n",
    "\n",
    "**Note**: The benefit of using _multiple strings_ :\n",
    "```Python\n",
    "varname = \"line 1 of text\"\n",
    "          \"line 2 of text\"\n",
    "```\n",
    "\n",
    "versus the _triple quote docstring_:\n",
    "```Python\n",
    "varname = \"\"\"line 1 of text\n",
    "             line 2 of text\n",
    "          \"\"\"\n",
    "```\n",
    "is that it can avoid adding those whitespaces and newline characters, making it better formatted to be passed to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "planner = Agent(\n",
    "    role=\"Content Planner\",\n",
    "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
    "    backstory=\"You're working on planning a blog article \"\n",
    "              \"about the topic: {topic}.\"\n",
    "              \"You collect information that helps the \"\n",
    "              \"audience learn something \"\n",
    "              \"and make informed decisions. \"\n",
    "              \"Your work is the basis for \"\n",
    "              \"the Content Writer to write an article on this topic.\",\n",
    "    allow_delegation=False,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent: Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 370
   },
   "outputs": [],
   "source": [
    "writer = Agent(\n",
    "    role=\"Content Writer\",\n",
    "    goal=\"Write insightful and factually accurate \"\n",
    "         \"opinion piece about the topic: {topic}\",\n",
    "    backstory=\"You're working on a writing \"\n",
    "              \"a new opinion piece about the topic: {topic}. \"\n",
    "              \"You base your writing on the work of \"\n",
    "              \"the Content Planner, who provides an outline \"\n",
    "              \"and relevant context about the topic. \"\n",
    "              \"You follow the main objectives and \"\n",
    "              \"direction of the outline, \"\n",
    "              \"as provide by the Content Planner. \"\n",
    "              \"You also provide objective and impartial insights \"\n",
    "              \"and back them up with information \"\n",
    "              \"provide by the Content Planner. \"\n",
    "              \"You acknowledge in your opinion piece \"\n",
    "              \"when your statements are opinions \"\n",
    "              \"as opposed to objective statements.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent: Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "editor = Agent(\n",
    "    role=\"Editor\",\n",
    "    goal=\"Edit a given blog post to align with \"\n",
    "         \"the writing style of the organization. \",\n",
    "    backstory=\"You are an editor who receives a blog post \"\n",
    "              \"from the Content Writer. \"\n",
    "              \"Your goal is to review the blog post \"\n",
    "              \"to ensure that it follows journalistic best practices,\"\n",
    "              \"provides balanced viewpoints \"\n",
    "              \"when providing opinions or assertions, \"\n",
    "              \"and also avoids major controversial topics \"\n",
    "              \"or opinions when possible.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tasks\n",
    "\n",
    "- Define your Tasks, and provide them a `description`, `expected_output` and `agent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "plan = Task(\n",
    "    description=(\n",
    "        \"1. Prioritize the latest trends, key players, \"\n",
    "            \"and noteworthy news on {topic}.\\n\"\n",
    "        \"2. Identify the target audience, considering \"\n",
    "            \"their interests and pain points.\\n\"\n",
    "        \"3. Develop a detailed content outline including \"\n",
    "            \"an introduction, key points, and a call to action.\\n\"\n",
    "        \"4. Include SEO keywords and relevant data or sources.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive content plan document \"\n",
    "        \"with an outline, audience analysis, \"\n",
    "        \"SEO keywords, and resources.\",\n",
    "    agent=planner,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "write = Task(\n",
    "    description=(\n",
    "        \"1. Use the content plan to craft a compelling \"\n",
    "            \"blog post on {topic}.\\n\"\n",
    "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
    "\t\t\"3. Sections/Subtitles are properly named \"\n",
    "            \"in an engaging manner.\\n\"\n",
    "        \"4. Ensure the post is structured with an \"\n",
    "            \"engaging introduction, insightful body, \"\n",
    "            \"and a summarizing conclusion.\\n\"\n",
    "        \"5. Proofread for grammatical errors and \"\n",
    "            \"alignment with the brand's voice.\\n\"\n",
    "    ),\n",
    "    expected_output=\"A well-written blog post \"\n",
    "        \"in markdown format, ready for publication, \"\n",
    "        \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "edit = Task(\n",
    "    description=(\"Proofread the given blog post for \"\n",
    "                 \"grammatical errors and \"\n",
    "                 \"alignment with the brand's voice.\"),\n",
    "    expected_output=\"A well-written blog post in markdown format, \"\n",
    "                    \"ready for publication, \"\n",
    "                    \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=editor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Crew\n",
    "\n",
    "- Create your crew of Agents\n",
    "- Pass the tasks to be performed by those agents.\n",
    "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
    "- `verbose=2` allows you to see all the logs of the execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[planner, writer, editor],\n",
    "    tasks=[plan, write, edit],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence.\n",
      "2. Identify the target audience, considering their interests and pain points.\n",
      "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
      "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Title: The Evolution of Artificial Intelligence: Trends, Players, and News\n",
      "\n",
      "Outline:\n",
      "I. Introduction\n",
      "    A. Definition of Artificial Intelligence\n",
      "    B. Importance of AI in today’s world\n",
      "II. Latest Trends in Artificial Intelligence\n",
      "    A. Machine Learning advancements\n",
      "    B. Natural Language Processing innovations\n",
      "    C. Robotics applications\n",
      "III. Key Players in the AI Industry\n",
      "    A. Tech giants like Google, Microsoft, and Amazon\n",
      "    B. AI startups disrupting the industry\n",
      "IV. Noteworthy News in Artificial Intelligence\n",
      "    A. Breakthrough research studies\n",
      "    B. Industry collaborations and partnerships\n",
      "V. Target Audience Analysis\n",
      "    A. Professionals in tech and innovation fields\n",
      "    B. Business owners looking to integrate AI\n",
      "    C. Students interested in AI careers\n",
      "VI. SEO Keywords\n",
      "    A. Artificial Intelligence trends\n",
      "    B. Top players in AI industry\n",
      "    C. Latest news on Artificial Intelligence\n",
      "VII. Resources\n",
      "    A. Forbes - AI news section\n",
      "    B. Gartner’s AI research reports\n",
      "    C. OpenAI blog for cutting-edge AI advancements\n",
      "\n",
      "Call to Action:\n",
      "Stay informed about the latest trends and news in Artificial Intelligence. Subscribe to industry-leading AI publications and follow top players in the AI space for updates.\n",
      "\n",
      "By following this content plan, the blog article on Artificial Intelligence will provide readers with a comprehensive overview of the industry's latest trends, key players, and noteworthy news, catering to a target audience interested in AI's advancements and applications. The use of SEO keywords and reliable resources will ensure the content is engaging, informative, and optimized for search engines.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Use the content plan to craft a compelling blog post on Artificial Intelligence.\n",
      "2. Incorporate SEO keywords naturally.\n",
      "3. Sections/Subtitles are properly named in an engaging manner.\n",
      "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
      "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "# The Evolution of Artificial Intelligence: Trends, Players, and News\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, notably computer systems. Today, AI plays a pivotal role in transforming various industries, revolutionizing processes, and enhancing productivity. From speech recognition to decision-making, AI technologies are shaping the future by enabling machines to learn from data, adapt to new inputs, and perform human-like tasks.\n",
      "\n",
      "## Latest Trends in Artificial Intelligence\n",
      "\n",
      "### Machine Learning Advancements\n",
      "One of the most significant trends in AI is the rapid advancement of machine learning algorithms. These algorithms allow computers to learn from and make predictions or decisions based on data, enabling them to perform tasks without explicit programming. Key applications include personalized recommendations, image recognition, and predictive analytics.\n",
      "\n",
      "### Natural Language Processing Innovations\n",
      "Natural Language Processing (NLP) has seen remarkable progress in recent years, with machines becoming increasingly proficient at understanding and generating human language. This trend has led to the development of virtual assistants, language translation tools, and sentiment analysis applications that enhance human-machine interactions.\n",
      "\n",
      "### Robotics Applications\n",
      "AI-powered robotics is another emerging trend, with robots being equipped with AI capabilities to perform tasks autonomously in various settings. From manufacturing to healthcare, robots are assisting humans in repetitive or hazardous tasks, showcasing the fusion of AI and robotics to drive efficiency and innovation.\n",
      "\n",
      "## Key Players in the AI Industry\n",
      "\n",
      "### Tech Giants like Google, Microsoft, and Amazon\n",
      "Leading tech companies such as Google, Microsoft, and Amazon are at the forefront of AI innovation, investing heavily in research and development to create cutting-edge AI solutions. These companies leverage AI across their products and services, from search algorithms to virtual assistants, shaping the industry's landscape with their technological prowess.\n",
      "\n",
      "### AI Startups Disrupting the Industry\n",
      "In addition to established players, AI startups are making significant waves in the industry by introducing novel ideas and disruptive technologies. These startups bring fresh perspectives and agile approaches to AI development, challenging traditional norms and driving rapid innovation in areas like healthcare, finance, and autonomous systems.\n",
      "\n",
      "## Noteworthy News in Artificial Intelligence\n",
      "\n",
      "### Breakthrough Research Studies\n",
      "Recent years have witnessed groundbreaking research studies in AI, ranging from advancements in deep learning to breakthroughs in neural networks. These studies push the boundaries of AI capabilities, opening new possibilities for applications in areas such as healthcare diagnostics, climate modeling, and autonomous driving.\n",
      "\n",
      "### Industry Collaborations and Partnerships\n",
      "Collaborations and partnerships between industry players have also been a notable trend, with companies joining forces to leverage each other's expertise and resources for mutual benefit. These initiatives foster innovation, accelerate product development, and drive the adoption of AI technologies in diverse sectors, highlighting the importance of collaboration in advancing the AI industry.\n",
      "\n",
      "## Target Audience Analysis\n",
      "\n",
      "### Professionals in Tech and Innovation Fields\n",
      "For professionals working in technology and innovation fields, staying updated on AI trends, players, and news is crucial to remain competitive and drive technological advancements within their organizations.\n",
      "\n",
      "### Business Owners Looking to Integrate AI\n",
      "Business owners seeking to enhance their operations and customer experiences through AI integration can benefit from insights into the latest AI trends, key industry players, and news updates to make informed decisions about AI adoption.\n",
      "\n",
      "### Students Interested in AI Careers\n",
      "Aspiring professionals pursuing careers in AI can gain valuable knowledge from understanding the industry's trends, prominent players, and recent developments, guiding them in choosing specializations and skill development paths for successful AI careers.\n",
      "\n",
      "## SEO Keywords\n",
      "\n",
      "Artificial Intelligence trends, Top players in AI industry, Latest news on Artificial Intelligence\n",
      "\n",
      "## Resources\n",
      "\n",
      "- [Forbes - AI news section](https://www.forbes.com/ai/)\n",
      "- [Gartner’s AI research reports](https://www.gartner.com/en/information-technology)\n",
      "- [OpenAI blog for cutting-edge AI advancements](https://www.openai.com/blog/)\n",
      "\n",
      "In conclusion, by exploring the evolution of Artificial Intelligence through the latest trends, insights into key players, noteworthy news, and target audience analysis, it becomes evident that AI continues to shape and redefine industries worldwide. Embracing AI advancements, staying informed about the industry's developments through reliable resources, and following top players in the AI space are essential steps to navigate the dynamic landscape of Artificial Intelligence effectively. Stay informed, stay ahead in the world of Artificial Intelligence.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEditor\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mProofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEditor\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "# The Evolution of Artificial Intelligence: Trends, Players, and News\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, notably computer systems. Today, AI plays a pivotal role in transforming various industries, revolutionizing processes, and enhancing productivity. From speech recognition to decision-making, AI technologies are shaping the future by enabling machines to learn from data, adapt to new inputs, and perform human-like tasks.\n",
      "\n",
      "## Latest Trends in Artificial Intelligence\n",
      "\n",
      "### Machine Learning Advancements\n",
      "One of the most significant trends in AI is the rapid advancement of machine learning algorithms. These algorithms allow computers to learn from and make predictions or decisions based on data, enabling them to perform tasks without explicit programming. Key applications include personalized recommendations, image recognition, and predictive analytics.\n",
      "\n",
      "### Natural Language Processing Innovations\n",
      "Natural Language Processing (NLP) has seen remarkable progress in recent years, with machines becoming increasingly proficient at understanding and generating human language. This trend has led to the development of virtual assistants, language translation tools, and sentiment analysis applications that enhance human-machine interactions.\n",
      "\n",
      "### Robotics Applications\n",
      "AI-powered robotics is another emerging trend, with robots being equipped with AI capabilities to perform tasks autonomously in various settings. From manufacturing to healthcare, robots are assisting humans in repetitive or hazardous tasks, showcasing the fusion of AI and robotics to drive efficiency and innovation.\n",
      "\n",
      "## Key Players in the AI Industry\n",
      "\n",
      "### Tech Giants like Google, Microsoft, and Amazon\n",
      "Leading tech companies such as Google, Microsoft, and Amazon are at the forefront of AI innovation, investing heavily in research and development to create cutting-edge AI solutions. These companies leverage AI across their products and services, from search algorithms to virtual assistants, shaping the industry's landscape with their technological prowess.\n",
      "\n",
      "### AI Startups Disrupting the Industry\n",
      "In addition to established players, AI startups are making significant waves in the industry by introducing novel ideas and disruptive technologies. These startups bring fresh perspectives and agile approaches to AI development, challenging traditional norms and driving rapid innovation in areas like healthcare, finance, and autonomous systems.\n",
      "\n",
      "## Noteworthy News in Artificial Intelligence\n",
      "\n",
      "### Breakthrough Research Studies\n",
      "Recent years have witnessed groundbreaking research studies in AI, ranging from advancements in deep learning to breakthroughs in neural networks. These studies push the boundaries of AI capabilities, opening new possibilities for applications in areas such as healthcare diagnostics, climate modeling, and autonomous driving.\n",
      "\n",
      "### Industry Collaborations and Partnerships\n",
      "Collaborations and partnerships between industry players have also been a notable trend, with companies joining forces to leverage each other's expertise and resources for mutual benefit. These initiatives foster innovation, accelerate product development, and drive the adoption of AI technologies in diverse sectors, highlighting the importance of collaboration in advancing the AI industry.\n",
      "\n",
      "## Target Audience Analysis\n",
      "\n",
      "### Professionals in Tech and Innovation Fields\n",
      "For professionals working in technology and innovation fields, staying updated on AI trends, players, and news is crucial to remain competitive and drive technological advancements within their organizations.\n",
      "\n",
      "### Business Owners Looking to Integrate AI\n",
      "Business owners seeking to enhance their operations and customer experiences through AI integration can benefit from insights into the latest AI trends, key industry players, and news updates to make informed decisions about AI adoption.\n",
      "\n",
      "### Students Interested in AI Careers\n",
      "Aspiring professionals pursuing careers in AI can gain valuable knowledge from understanding the industry's trends, prominent players, and recent developments, guiding them in choosing specializations and skill development paths for successful AI careers.\n",
      "\n",
      "## SEO Keywords\n",
      "\n",
      "Artificial Intelligence trends, Top players in AI industry, Latest news on Artificial Intelligence\n",
      "\n",
      "## Resources\n",
      "\n",
      "- [Forbes - AI news section](https://www.forbes.com/ai/)\n",
      "- [Gartner’s AI research reports](https://www.gartner.com/en/information-technology)\n",
      "- [OpenAI blog for cutting-edge AI advancements](https://www.openai.com/blog/)\n",
      "\n",
      "In conclusion, by exploring the evolution of Artificial Intelligence through the latest trends, insights into key players, noteworthy news, and target audience analysis, it becomes evident that AI continues to shape and redefine industries worldwide. Embracing AI advancements, staying informed about the industry's developments through reliable resources, and following top players in the AI space are essential steps to navigate the dynamic landscape of Artificial Intelligence effectively. Stay informed, stay ahead in the world of Artificial Intelligence.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the results of your execution as markdown in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Unleashing the Power of Crew AI for Patent Drafting: Best Practices Unveiled\n",
       "\n",
       "## Introduction\n",
       "\n",
       "In the ever-changing landscape of intellectual property, artificial intelligence (AI) has made a significant impact on various processes, particularly patent drafting. Crew AI, an innovative AI tool, has become well-known for its efficiency and effectiveness in supporting patent professionals and innovators in creating high-quality patents. By harnessing the capabilities of Crew AI, individuals can boost their productivity and accuracy, leading to the development of stronger patent applications.\n",
       "\n",
       "## Understanding the Target Audience\n",
       "\n",
       "The target audience for utilizing Crew AI in patent drafting includes patent attorneys, patent agents, and inventors or innovators who operate within the intricate realm of intellectual property. These individuals aim to navigate the complexities of patent drafting with precision and ingenuity. By comprehending the unique requirements and obstacles faced by this audience, we can tailor our approach to offer the most valuable insights and recommendations.\n",
       "\n",
       "## Best Practices for Using Crew AI in Patent Drafting\n",
       "\n",
       "### Setting Clear Objectives\n",
       "\n",
       "Prior to commencing patent drafting with Crew AI, it is imperative to define clear objectives for the process. Establishing the scope of the patent application, identifying key innovative aspects to emphasize, and outlining the technical details to be included are essential steps. Precise goal-setting will enable the AI tool to effectively aid in achieving the desired outcomes.\n",
       "\n",
       "### Understanding Patent Requirements\n",
       "\n",
       "Successful patent drafting demands a deep understanding of the legal and technical components involved. Familiarizing oneself with the specific requirements of patent applications, such as patentability criteria, disclosure requirements, and formalities, is crucial. While Crew AI can assist in interpreting intricate patent laws and guidelines, a solid knowledge base in patent drafting is fundamental for optimal results.\n",
       "\n",
       "### Leveraging AI Features\n",
       "\n",
       "Exploit the diverse range of AI features provided by Crew AI to maximize its potential in patent drafting. Make use of functionalities like natural language processing for formulating patent claims, semantic analysis for improving description clarity, and automated review tools for detecting errors. Integrating these AI capabilities into your workflow can significantly streamline the drafting process.\n",
       "\n",
       "### Ensuring Accuracy and Compliance\n",
       "\n",
       "Despite the powerful capabilities of AI tools in patent drafting, it is vital to verify the accuracy and compliance of the content produced. Regularly reviewing the output generated by Crew AI to confirm the correctness of technical descriptions, claims, and specifications is essential. Adhering to patent regulations and guidelines is imperative to uphold the authenticity and integrity of the patent application.\n",
       "\n",
       "### Reviewing and Polishing the Draft\n",
       "\n",
       "A crucial final step in leveraging Crew AI for patent drafting involves thorough review and refinement of the draft. Engage in manual editing and enhancement to elevate the clarity, coherence, and conciseness of the patent application. Human intervention plays a pivotal role in refining the output generated by AI, ensuring that the final draft meets the highest standards of quality and comprehensiveness.\n",
       "\n",
       "## Call to Action\n",
       "\n",
       "To delve deeper into the capabilities of Crew AI in patent drafting, we urge readers to experience the efficiency and innovation it brings to the process. Embrace the future of patent drafting tools by integrating Crew AI into your workflow. For additional guidance and support in utilizing AI for patents, do not hesitate to reach out to our team for personalized assistance.\n",
       "\n",
       "## SEO Keywords\n",
       "Crew AI, patent drafting, artificial intelligence in patents, patent writing tools, patent attorney software\n",
       "\n",
       "## Resources\n",
       "- **USPTO**: United States Patent and Trademark Office\n",
       "- **WIPO**: World Intellectual Property Organization\n",
       "- **IAM**: Intellectual Asset Management\n",
       "\n",
       "In conclusion, the utilization of Crew AI in patent drafting offers a significant opportunity for patent professionals and innovators to enhance their efficiency and precision in creating high-quality patent applications. By adhering to the best practices outlined above and capitalizing on the advanced capabilities of Crew AI, individuals can streamline their patent drafting process and enhance the quality of their patent submissions. Embrace the power of AI in patents and embark on a journey towards greater innovation and success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Modify the display code to access the raw string content\n",
    "from IPython.display import Markdown\n",
    "Markdown(result.raw)  # Access the .raw attribute of the CrewOutput object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it Yourself\n",
    "\n",
    "- Pass in a topic of your choice and see what the agents come up with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Prioritize the latest trends, key players, and noteworthy news on Best practices for using Crew AI to write patents.\n",
      "2. Identify the target audience, considering their interests and pain points.\n",
      "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
      "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Title: Unleashing the Power of Crew AI for Patent Drafting: Best Practices Unveiled\n",
      "\n",
      "Outline:\n",
      "I. Introduction\n",
      "    A. Definition of Crew AI\n",
      "    B. Importance of Crew AI in patent drafting\n",
      "II. Understanding the Target Audience\n",
      "    A. Patent Attorneys \n",
      "    B. Patent Agents \n",
      "    C. Inventors and Innovators \n",
      "III. Best Practices for Using Crew AI in Patent Drafting\n",
      "    A. Setting Clear Objectives \n",
      "    B. Understanding Patent Requirements \n",
      "    C. Leveraging AI Features \n",
      "    D. Ensuring Accuracy and Compliance \n",
      "    E. Reviewing and Polishing the Draft \n",
      "IV. Call to Action\n",
      "    A. Encouraging Readers to Try Crew AI for Patent Writing \n",
      "    B. Providing Contact Information for Further Assistance \n",
      "V. SEO Keywords: Crew AI, patent drafting, artificial intelligence in patents, patent writing tools, patent attorney software\n",
      "VI. Resources:\n",
      "    A. USPTO: United States Patent and Trademark Office\n",
      "    B. WIPO: World Intellectual Property Organization\n",
      "    C. IAM: Intellectual Asset Management\n",
      "\n",
      "Target Audience Analysis:\n",
      "The target audience for this content includes patent attorneys, patent agents, and inventors or innovators who are involved in the patent drafting process. They are interested in improving their efficiency and accuracy in drafting patents while also staying updated with technological advancements in the field. The pain points of this audience involve time-consuming manual processes, complex patent requirements, and the need for precision in patent drafting.\n",
      "\n",
      "By addressing the best practices for using Crew AI to write patents, this content aims to provide practical guidance to the audience, helping them utilize AI technology effectively to streamline their patent drafting process and enhance the quality of their patent applications.\n",
      "\n",
      "This comprehensive content plan aims to engage the target audience with valuable insights, actionable tips, and relevant resources, ultimately empowering them to optimize their patent drafting process using Crew AI.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Use the content plan to craft a compelling blog post on Best practices for using Crew AI to write patents.\n",
      "2. Incorporate SEO keywords naturally.\n",
      "3. Sections/Subtitles are properly named in an engaging manner.\n",
      "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
      "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "# Unleashing the Power of Crew AI for Patent Drafting: Best Practices Unveiled\n",
      "\n",
      "## Introduction\n",
      "\n",
      "In the fast-evolving world of intellectual property, the emergence of artificial intelligence (AI) has revolutionized various processes, including patent drafting. Crew AI, a cutting-edge AI tool, has gained prominence for its efficiency and effectiveness in assisting patent professionals and innovators in drafting high-quality patents. By harnessing the power of Crew AI, individuals can enhance their productivity and accuracy, ultimately leading to stronger patent applications.\n",
      "\n",
      "## Understanding the Target Audience\n",
      "\n",
      "The audience for utilizing Crew AI in patent drafting comprises patent attorneys, patent agents, and inventors or innovators involved in the complex world of intellectual property. These individuals seek to navigate the intricate landscape of patent drafting with precision and innovation. By understanding the unique needs and challenges of this audience, we can tailor our approach to provide the most valuable insights and guidance.\n",
      "\n",
      "## Best Practices for Using Crew AI in Patent Drafting\n",
      "\n",
      "### Setting Clear Objectives\n",
      "\n",
      "Before diving into patent drafting using Crew AI, it is crucial to establish clear objectives for the process. Define the scope of the patent application, identify key innovative aspects to highlight, and outline the technical details that need to be included. Setting precise goals will ensure that the AI tool efficiently assists in achieving the desired outcomes.\n",
      "\n",
      "### Understanding Patent Requirements\n",
      "\n",
      "Patent drafting requires a deep understanding of the legal and technical aspects involved. Familiarize yourself with the specific requirements of patent applications, including patentability criteria, disclosure requirements, and formalities. Crew AI can aid in interpreting complex patent laws and guidelines, but a solid foundation of knowledge in patent drafting is essential for optimal results.\n",
      "\n",
      "### Leveraging AI Features\n",
      "\n",
      "Explore the full range of AI features offered by Crew AI to maximize its potential in drafting patents. Utilize functionalities such as natural language processing for generating patent claims, semantic analysis for enhancing the clarity of descriptions, and automated review tools for error detection. Integrating these AI capabilities into your workflow can significantly streamline the drafting process.\n",
      "\n",
      "### Ensuring Accuracy and Compliance\n",
      "\n",
      "While AI tools are powerful assets in patent drafting, it is crucial to ensure the accuracy and compliance of the drafted content. Regularly review the output generated by Crew AI to verify the correctness of technical descriptions, claims, and specifications. Adhere to patent regulations and guidelines to maintain the authenticity and integrity of the patent application.\n",
      "\n",
      "### Reviewing and Polishing the Draft\n",
      "\n",
      "A final crucial step in utilizing Crew AI for patent drafting is the thorough review and polishing of the draft. Engage in manual editing and refinement to enhance the clarity, coherence, and conciseness of the patent application. Human intervention plays a vital role in refining the output generated by AI, ensuring that the final draft meets the highest standards of quality and comprehensiveness.\n",
      "\n",
      "## Call to Action\n",
      "\n",
      "To further explore the capabilities of Crew AI in patent drafting, we encourage readers to experience the efficiency and innovation it brings to the process. Embrace the future of patent writing tools by integrating Crew AI into your workflow. For additional assistance and support in leveraging AI for patents, feel free to reach out to our team for personalized guidance.\n",
      "\n",
      "## SEO Keywords\n",
      "Crew AI, patent drafting, artificial intelligence in patents, patent writing tools, patent attorney software\n",
      "\n",
      "## Resources\n",
      "- **USPTO**: United States Patent and Trademark Office\n",
      "- **WIPO**: World Intellectual Property Organization\n",
      "- **IAM**: Intellectual Asset Management\n",
      "\n",
      "In conclusion, the utilization of Crew AI in patent drafting presents a significant opportunity for patent professionals and innovators to enhance their efficiency and precision in generating high-quality patent applications. By following the best practices outlined above and leveraging the advanced capabilities of Crew AI, individuals can streamline their patent drafting process and elevate the standard of their patent submissions. Embrace the power of AI in patents and embark on a journey towards greater innovation and success.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEditor\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mProofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEditor\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "# Unleashing the Power of Crew AI for Patent Drafting: Best Practices Unveiled\n",
      "\n",
      "## Introduction\n",
      "\n",
      "In the ever-changing landscape of intellectual property, artificial intelligence (AI) has made a significant impact on various processes, particularly patent drafting. Crew AI, an innovative AI tool, has become well-known for its efficiency and effectiveness in supporting patent professionals and innovators in creating high-quality patents. By harnessing the capabilities of Crew AI, individuals can boost their productivity and accuracy, leading to the development of stronger patent applications.\n",
      "\n",
      "## Understanding the Target Audience\n",
      "\n",
      "The target audience for utilizing Crew AI in patent drafting includes patent attorneys, patent agents, and inventors or innovators who operate within the intricate realm of intellectual property. These individuals aim to navigate the complexities of patent drafting with precision and ingenuity. By comprehending the unique requirements and obstacles faced by this audience, we can tailor our approach to offer the most valuable insights and recommendations.\n",
      "\n",
      "## Best Practices for Using Crew AI in Patent Drafting\n",
      "\n",
      "### Setting Clear Objectives\n",
      "\n",
      "Prior to commencing patent drafting with Crew AI, it is imperative to define clear objectives for the process. Establishing the scope of the patent application, identifying key innovative aspects to emphasize, and outlining the technical details to be included are essential steps. Precise goal-setting will enable the AI tool to effectively aid in achieving the desired outcomes.\n",
      "\n",
      "### Understanding Patent Requirements\n",
      "\n",
      "Successful patent drafting demands a deep understanding of the legal and technical components involved. Familiarizing oneself with the specific requirements of patent applications, such as patentability criteria, disclosure requirements, and formalities, is crucial. While Crew AI can assist in interpreting intricate patent laws and guidelines, a solid knowledge base in patent drafting is fundamental for optimal results.\n",
      "\n",
      "### Leveraging AI Features\n",
      "\n",
      "Exploit the diverse range of AI features provided by Crew AI to maximize its potential in patent drafting. Make use of functionalities like natural language processing for formulating patent claims, semantic analysis for improving description clarity, and automated review tools for detecting errors. Integrating these AI capabilities into your workflow can significantly streamline the drafting process.\n",
      "\n",
      "### Ensuring Accuracy and Compliance\n",
      "\n",
      "Despite the powerful capabilities of AI tools in patent drafting, it is vital to verify the accuracy and compliance of the content produced. Regularly reviewing the output generated by Crew AI to confirm the correctness of technical descriptions, claims, and specifications is essential. Adhering to patent regulations and guidelines is imperative to uphold the authenticity and integrity of the patent application.\n",
      "\n",
      "### Reviewing and Polishing the Draft\n",
      "\n",
      "A crucial final step in leveraging Crew AI for patent drafting involves thorough review and refinement of the draft. Engage in manual editing and enhancement to elevate the clarity, coherence, and conciseness of the patent application. Human intervention plays a pivotal role in refining the output generated by AI, ensuring that the final draft meets the highest standards of quality and comprehensiveness.\n",
      "\n",
      "## Call to Action\n",
      "\n",
      "To delve deeper into the capabilities of Crew AI in patent drafting, we urge readers to experience the efficiency and innovation it brings to the process. Embrace the future of patent drafting tools by integrating Crew AI into your workflow. For additional guidance and support in utilizing AI for patents, do not hesitate to reach out to our team for personalized assistance.\n",
      "\n",
      "## SEO Keywords\n",
      "Crew AI, patent drafting, artificial intelligence in patents, patent writing tools, patent attorney software\n",
      "\n",
      "## Resources\n",
      "- **USPTO**: United States Patent and Trademark Office\n",
      "- **WIPO**: World Intellectual Property Organization\n",
      "- **IAM**: Intellectual Asset Management\n",
      "\n",
      "In conclusion, the utilization of Crew AI in patent drafting offers a significant opportunity for patent professionals and innovators to enhance their efficiency and precision in creating high-quality patent applications. By adhering to the best practices outlined above and capitalizing on the advanced capabilities of Crew AI, individuals can streamline their patent drafting process and enhance the quality of their patent submissions. Embrace the power of AI in patents and embark on a journey towards greater innovation and success.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = \"Best practices for using Crew AI to write patents\"\n",
    "result = crew.kickoff(inputs={\"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Unleashing the Power of Crew AI for Patent Drafting: Best Practices Unveiled\n",
       "\n",
       "## Introduction\n",
       "\n",
       "In the ever-changing landscape of intellectual property, artificial intelligence (AI) has made a significant impact on various processes, particularly patent drafting. Crew AI, an innovative AI tool, has become well-known for its efficiency and effectiveness in supporting patent professionals and innovators in creating high-quality patents. By harnessing the capabilities of Crew AI, individuals can boost their productivity and accuracy, leading to the development of stronger patent applications.\n",
       "\n",
       "## Understanding the Target Audience\n",
       "\n",
       "The target audience for utilizing Crew AI in patent drafting includes patent attorneys, patent agents, and inventors or innovators who operate within the intricate realm of intellectual property. These individuals aim to navigate the complexities of patent drafting with precision and ingenuity. By comprehending the unique requirements and obstacles faced by this audience, we can tailor our approach to offer the most valuable insights and recommendations.\n",
       "\n",
       "## Best Practices for Using Crew AI in Patent Drafting\n",
       "\n",
       "### Setting Clear Objectives\n",
       "\n",
       "Prior to commencing patent drafting with Crew AI, it is imperative to define clear objectives for the process. Establishing the scope of the patent application, identifying key innovative aspects to emphasize, and outlining the technical details to be included are essential steps. Precise goal-setting will enable the AI tool to effectively aid in achieving the desired outcomes.\n",
       "\n",
       "### Understanding Patent Requirements\n",
       "\n",
       "Successful patent drafting demands a deep understanding of the legal and technical components involved. Familiarizing oneself with the specific requirements of patent applications, such as patentability criteria, disclosure requirements, and formalities, is crucial. While Crew AI can assist in interpreting intricate patent laws and guidelines, a solid knowledge base in patent drafting is fundamental for optimal results.\n",
       "\n",
       "### Leveraging AI Features\n",
       "\n",
       "Exploit the diverse range of AI features provided by Crew AI to maximize its potential in patent drafting. Make use of functionalities like natural language processing for formulating patent claims, semantic analysis for improving description clarity, and automated review tools for detecting errors. Integrating these AI capabilities into your workflow can significantly streamline the drafting process.\n",
       "\n",
       "### Ensuring Accuracy and Compliance\n",
       "\n",
       "Despite the powerful capabilities of AI tools in patent drafting, it is vital to verify the accuracy and compliance of the content produced. Regularly reviewing the output generated by Crew AI to confirm the correctness of technical descriptions, claims, and specifications is essential. Adhering to patent regulations and guidelines is imperative to uphold the authenticity and integrity of the patent application.\n",
       "\n",
       "### Reviewing and Polishing the Draft\n",
       "\n",
       "A crucial final step in leveraging Crew AI for patent drafting involves thorough review and refinement of the draft. Engage in manual editing and enhancement to elevate the clarity, coherence, and conciseness of the patent application. Human intervention plays a pivotal role in refining the output generated by AI, ensuring that the final draft meets the highest standards of quality and comprehensiveness.\n",
       "\n",
       "## Call to Action\n",
       "\n",
       "To delve deeper into the capabilities of Crew AI in patent drafting, we urge readers to experience the efficiency and innovation it brings to the process. Embrace the future of patent drafting tools by integrating Crew AI into your workflow. For additional guidance and support in utilizing AI for patents, do not hesitate to reach out to our team for personalized assistance.\n",
       "\n",
       "## SEO Keywords\n",
       "Crew AI, patent drafting, artificial intelligence in patents, patent writing tools, patent attorney software\n",
       "\n",
       "## Resources\n",
       "- **USPTO**: United States Patent and Trademark Office\n",
       "- **WIPO**: World Intellectual Property Organization\n",
       "- **IAM**: Intellectual Asset Management\n",
       "\n",
       "In conclusion, the utilization of Crew AI in patent drafting offers a significant opportunity for patent professionals and innovators to enhance their efficiency and precision in creating high-quality patent applications. By adhering to the best practices outlined above and capitalizing on the advanced capabilities of Crew AI, individuals can streamline their patent drafting process and enhance the quality of their patent submissions. Embrace the power of AI in patents and embark on a journey towards greater innovation and success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    " ## Other Popular Models as LLM for your Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face (HuggingFaceHub endpoint)\n",
    "\n",
    "```Python\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    huggingfacehub_api_token=\"<HF_TOKEN_HERE>\",\n",
    "    task=\"text-generation\",\n",
    ")\n",
    "\n",
    "### you will pass \"llm\" to your agent function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mistral API\n",
    "\n",
    "```Python\n",
    "OPENAI_API_KEY=your-mistral-api-key\n",
    "OPENAI_API_BASE=https://api.mistral.ai/v1\n",
    "OPENAI_MODEL_NAME=\"mistral-small\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohere\n",
    "\n",
    "```Python\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "# Initialize language model\n",
    "os.environ[\"COHERE_API_KEY\"] = \"your-cohere-api-key\"\n",
    "llm = ChatCohere()\n",
    "\n",
    "### you will pass \"llm\" to your agent function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For using Llama locally with Ollama and more, checkout the crewAI documentation on [Connecting to any LLM](https://docs.crewai.com/how-to/LLM-Connections/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
